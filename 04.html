<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#tensorflow-2-basics">TensorFlow 2 Basics</a></li>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#about-this-exercise">About This Exercise</a></li>
<li><a href="#objectives">Objectives</a></li>
</ul>
</li>
<li><a href="#introduction-to-tensors">Introduction to Tensors</a>
<ul>
<li><a href="#tensor-creation">Tensor Creation</a></li>
<li><a href="#tensor-slicing-and-indexing">Tensor Slicing and Indexing</a></li>
<li><a href="#tensor-dimension-modification">Tensor Dimension Modification</a></li>
<li><a href="#arithmetic-operations-on-tensors">Arithmetic Operations on Tensors</a></li>
<li><a href="#dimension-based-arithmetic-operations">Dimension-based Arithmetic Operations</a></li>
<li><a href="#tensor-concatenation-and-splitting">Tensor Concatenation and Splitting</a></li>
<li><a href="#tensor-sorting">Tensor Sorting</a></li>
<li><a href="#eager-execution-mode-of-tensorflow-2">Eager Execution Mode of TensorFlow 2</a></li>
<li><a href="#autograph-of-tensorflow-2">AutoGraph of TensorFlow 2</a></li>
</ul>
</li>
<li><a href="#common-modules-of-tensorflow-2">Common Modules of TensorFlow 2</a>
<ul>
<li><a href="#introduction-1">Introduction</a></li>
<li><a href="#model-building">Model Building</a></li>
<li><a href="#training-and-evaluation">Training and Evaluation</a></li>
<li><a href="#model-saving-and-restoration">Model Saving and Restoration</a></li>
</ul>
</li>
<li><a href="#handwritten-digit-recognition-with-tensorflow">Handwritten Digit Recognition with TensorFlow</a>
<ul>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#project-description-and-dataset-acquisition">Project Description and Dataset Acquisition</a></li>
</ul>
</li>
<li><a href="#image-classification">Image Classification</a>
<ul>
<li><a href="#introduction-3">Introduction</a></li>
<li><a href="#tasks-1">Tasks</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="tensorflow-2-basics">TensorFlow 2 Basics</h1>
<h1 id="introduction">Introduction</h1>
<h2 id="about-this-exercise">About This Exercise</h2>
<p>This exercise introduces tensor operations of TensorFlow 2, including tensor creation, slicing, indexing, tensor dimension modification, tensor arithmetic operations, and tensor sorting, to help you understand the basic syntax of TensorFlow 2.</p>
<h2 id="objectives">Objectives</h2>
<p>Learn how to create tensors.<br>
Learn how to slice and index tensors.<br>
Master the syntax of tensor dimension changes.<br>
Master arithmetic operations of tensors.<br>
Know how to sort tensors.<br>
Understand eager execution and AutoGraph based on code.</p>
<hr>
<h1 id="introduction-to-tensors">Introduction to Tensors</h1>
<p>In TensorFlow, tensors are classified into constant and variable tensors.<br>
A defined constant tensor has an immutable value and dimension while a defined variable tensor has a variable value and an immutable dimension.<br>
In a neural network, a variable tensor is generally used as a matrix for storing weights and other information, and is a trainable data type. A constant tensor can be used as a variable for storing hyperparameters or other structural information.</p>
<h2 id="tensor-creation">Tensor Creation</h2>
<h3 id="creating-a-constant-tensor">Creating a Constant Tensor</h3>
<p>Common methods for creating a constant tensor include:</p>
<ul>
<li><code>tf.constant()</code>: creates a constant tensor.</li>
<li><code>tf.zeros()</code>, <code>tf.zeros_like()</code>, <code>tf.ones()</code>, <code>tf.ones_like()</code>: creates an all-zero or all-one constant tensor.</li>
<li><code>tf.fill()</code>: creates a tensor with a user-defined value.</li>
<li><code>tf.random</code>: creates a tensor with a known distribution.</li>
<li><code>tf.convert_to_tensor</code>: creates a list object by using NumPy and then converts it into a tensor.</li>
</ul>
<h4 id="step-1-tf.constant">Step 1 <code>tf.constant()</code></h4>
<ul>
<li><code>tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)</code>:
<ul>
<li><code>value</code>: value</li>
<li><code>dtype</code>: data type</li>
<li><code>shape</code>: tensor shape</li>
<li><code>name</code>: name for the constant tensor</li>
<li><code>verify_shape</code>: Boolean that enables verification of a shape of values. The default value is False. If verify_shape is set to True, the system checks whether the shape of value is consistent with shape. If they are inconsistent, an error is reported.</li>
</ul>
</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
const_a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token comment"># Create a 2x2 matrix with values 1, 2, 3, and 4.</span>
const_a
</code></pre>
<p>Output:</p>
<pre class=" language-bash"><code class="prism  language-bash">2.0.0-beta1
<span class="token operator">&lt;</span>tf.Tensor: shape<span class="token operator">=</span><span class="token punctuation">(</span>2, 2<span class="token punctuation">)</span>, dtype<span class="token operator">=</span>float32, numpy<span class="token operator">=</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>1., 2.<span class="token punctuation">]</span>,
       <span class="token punctuation">[</span>3., 4.<span class="token punctuation">]</span><span class="token punctuation">]</span>, dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span><span class="token operator">&gt;</span>
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># View common attributes.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"value of const_a: "</span><span class="token punctuation">,</span> const_a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data type of const_a: "</span><span class="token punctuation">,</span> const_a<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"shape of const_a: "</span><span class="token punctuation">,</span> const_a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"device that const_a will be generated: "</span><span class="token punctuation">,</span> const_a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>The value of const_a is [[1. 2.]
 [3. 4.]]
The data type of const_a is &lt;dtype: 'float32'&gt;
The shape of const_a is (2, 2).
device that const_a will be generated: /job:localhost/replica:0/task:0/device:CPU:0.
</code></pre>
<h4 id="step-2-tf.zeros-tf.zeros_like-tf.onestf.ones_like">Step 2 <code>tf.zeros()</code>, <code>tf.zeros_like()</code>, <code>tf.ones()</code>,<code>tf.ones_like()</code></h4>
<p>The usage of <code>tf.ones()</code> and <code>tf.ones_like()</code> is similar to that of <code>tf.zeros()</code> and <code>tf.zeros_like()</code>. Therefore, the following describes how to use <code>tf.ones()</code> and <code>tf.ones_like()</code>. Create a tensor with all elements set to zero.<br>
<code>tf.zeros(shape, dtype=tf.float32, name=None)</code>:</p>
<ul>
<li><code>shape</code>: tensor shape</li>
<li><code>dtype</code>: type</li>
<li><code>name</code>: name for the operation</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">zeros_b <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> <span class="token comment"># Create a 2x3 matrix with all element values being 0.</span>
</code></pre>
<p>Create a tensor with all elements set to zero based on the input tensor, with its shape being the same as that of the input tensor. <code>tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)</code>:</p>
<ul>
<li><code>input_tensor</code>: tensor</li>
<li><code>dtype</code>: type</li>
<li><code>name</code>: name for the operation</li>
<li><code>optimize</code>: optimize or not</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">zeros_like_c <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>const_a<span class="token punctuation">)</span>
<span class="token comment"># View generated data.</span>
zeros_like_c<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>array([[0., 0.],
       [0., 0.]], dtype=float32)
</code></pre>
<h4 id="step-3-tf.fill">Step 3 <code>tf.fill()</code></h4>
<p>Create a tensor and fill it with a specific value. <code>tf.fill(dims, value, name=None)</code>:</p>
<ul>
<li><code>dims</code>: tensor shape, which is the same as - the preceding shape</li>
<li><code>value</code>: tensor value</li>
<li><code>name</code>: name of the output</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">fill_d <span class="token operator">=</span> tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span> <span class="token comment"># 3x3 matrix with all element values being 8</span>
<span class="token comment"># View data.</span>
fill_d<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>array([[8, 8, 8],
       [8, 8, 8],
       [8, 8, 8]], dtype=int32)
</code></pre>
<h4 id="step-4-tf.random">Step 4 <code>tf.random</code></h4>
<p>This module is used to generate a tensor with a specific distribution. The common methods in this module include <code>tf.random.uniform()</code>, <code>tf.random.normal()</code>, and <code>tf.random.shuffle()</code>. The following demonstrates how to use <code>tf.random.normal()</code>.</p>
<p>Create a tensor that conforms to the normal distribution. <code>tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32,seed=None, name=None)</code>:</p>
<ul>
<li><code>shape</code>: data shape</li>
<li><code>mean</code>: mean value of Gaussian distribution</li>
<li><code>stddev</code>: standard deviation of Gaussian distribution</li>
<li><code>dtype</code>: data type</li>
<li><code>seed</code>: random seed</li>
<li><code>name</code>: name for the operation</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">random_e <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> seed <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># View the created data.</span>
random_e<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>array([[-0.8521641 ,  2.0672443 , -0.94127315,  1.7840577 ,  2.9919195 ],
       [-0.8644102 ,  0.41812655, -0.85865736,  1.0617154 ,  1.0575105 ],
       [ 0.22457163, -0.02204755,  0.5084496 , -0.09113179, -1.3036906 ],
       [-1.1108295 , -0.24195422,  2.8516252 , -0.7503834 ,  0.1267275 ],
       [ 0.9460202 ,  0.12648873, -2.6540542 ,  0.0853276 ,  0.01731399]],
      dtype=float32)
</code></pre>
<h4 id="step-5-create-a-list-object-by-using-numpy-and-then-convert-it-into-a-tensor-by-using-tf.convert_to_tensor.">Step 5 Create a list object by using NumPy and then convert it into a tensor by using <code>tf.convert_to_tensor</code>.</h4>
<p>This method can convert the given value to a tensor. It converts Python objects of various types to Tensor objects.<br>
<code>tf.convert_to_tensor(value,dtype=None,dtype_hint=None,name=None)</code>:</p>
<ul>
<li><code>value</code>: value to be converted</li>
<li><code>dtype</code>: tensor data type</li>
<li><code>dtype_hint</code>: optional element type for the returned tensor, used when dtype is None. In some cases, a caller may not have a dtype in mind when converting to a tensor, so <code>dtype_hint</code> can be used as a soft preference.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Create a list.</span>
list_f <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span>
<span class="token comment"># View the data type.</span>
<span class="token builtin">type</span><span class="token punctuation">(</span>list_f<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>list
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">tensor_f <span class="token operator">=</span> tf<span class="token punctuation">.</span>convert_to_tensor<span class="token punctuation">(</span>list_f<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
tensor_f
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6.], dtype=float32)&gt;
</code></pre>
<h3 id="creating-a-variable-tensor">Creating a Variable Tensor</h3>
<p>In TensorFlow, variables are created and tracked via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># To create a variable, provide an initial value.</span>
var_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
var_1
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=
array([[1., 1., 1.],
       [1., 1., 1.]], dtype=float32)&gt;
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Read the variable value.</span>
Print<span class="token punctuation">(</span><span class="token string">"value of var_1: "</span><span class="token punctuation">,</span>var_1<span class="token punctuation">.</span>read_value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># Assign a new value to the variable.</span>
var_value_1<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span> 
var_1<span class="token punctuation">.</span>assign<span class="token punctuation">(</span>var_value_1<span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"new value for var_1: "</span><span class="token punctuation">,</span>var_1<span class="token punctuation">.</span>read_value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Value of var_1: tf.Tensor(
[[1. 1. 1.]
 [1. 1. 1.]], shape=(2, 3), dtype=float32)
New value for var_1: tf.Tensor(
[[1. 2. 3.]
 [4. 5. 6.]], shape=(2, 3), dtype=float32)
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Add a value to this variable.</span>
var_1<span class="token punctuation">.</span>assign_add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
var_1
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=
array([[2., 3., 4.],
       [5., 6., 7.]], dtype=float32)&gt;
</code></pre>
<h2 id="tensor-slicing-and-indexing">Tensor Slicing and Indexing</h2>
<h3 id="slicing">Slicing</h3>
<p>Major slicing methods include:</p>
<ul>
<li><code>[start: end]</code>: extracts a data slice from the start position to the end position of a tensor.</li>
<li><code>[start :end :step]</code> or <code>[::step]</code>: extracts a data slice at an interval of step from the start position to the end position of a tensor.</li>
<li><code>[::-1]</code>: slices data from the last element.</li>
<li><code>'...'</code>: indicates a data slice of any length.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Create a 4-dimensional tensor. The tensor contains four images. The size of each image is 100 x 100 x 3.</span>
tensor_h <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor_h
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=
array([[[[ 1.68444023e-01, -7.46562362e-01, -4.34964240e-01],
         [-4.69263226e-01,  6.26460612e-01,  1.21065331e+00],
         [ 7.21675277e-01,  4.61057723e-01, -9.20868576e-01],
         ...,
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Extract the first image.</span>
tensor_h<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=
array([[[ 1.68444023e-01, -7.46562362e-01, -4.34964240e-01],
        [-4.69263226e-01,  6.26460612e-01,  1.21065331e+00],
        [ 7.21675277e-01,  4.61057723e-01, -9.20868576e-01],
        ...,
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Extract one slice every two images.</span>
tensor_h<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(2, 100, 100, 3), dtype=float32, numpy=
array([[[[ 1.68444023e-01, -7.46562362e-01, -4.34964240e-01],
         [-4.69263226e-01,  6.26460612e-01,  1.21065331e+00],
         [ 7.21675277e-01,  4.61057723e-01, -9.20868576e-01],
         ...,
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Slice data from the last element.</span>
tensor_h<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=
array([[[[-1.70684665e-01,  1.52386248e+00, -1.91677585e-01],
         [-1.78917408e+00, -7.48436213e-01,  6.10363662e-01],
         [ 7.64770031e-01,  6.06725179e-02,  1.32704067e+00],
         ...,
</code></pre>
<h3 id="indexing">Indexing</h3>
<p>The basic format of an index is <code>a[d1][d2][d3]</code>.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Obtain the pixel in the [20,40] position in the second channel of the first image.</span>
tensor_h<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.38231283&gt;
</code></pre>
<p>If the indexes to be extracted are nonconsecutive, <code>tf.gather</code> and <code>tf.gather_nd</code> are commonly used for data extraction in TensorFlow.<br>
To extract data from a particular dimension:</p>
<p><code>tf.gather(params, indices,axis=None)</code>:</p>
<ul>
<li><code>params</code>: input tensor</li>
<li><code>indices</code>: index of the data to be extracted</li>
<li><code>axis</code>: dimension of the data to be extracted<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Extract the first, second, and fourth images from tensor_h ([4,100,100,3]).</span>
indices <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>
tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>tensor_h<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>indices<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(3, 100, 100, 3), dtype=float32, numpy=
array([[[[ 1.68444023e-01, -7.46562362e-01, -4.34964240e-01],
         [-4.69263226e-01,  6.26460612e-01,  1.21065331e+00],
         [ 7.21675277e-01,  4.61057723e-01, -9.20868576e-01],
         ...,
</code></pre>
<p><code>tf.gather_nd allows</code> data extraction from multiple dimensions:<br>
<code>tf.gather_nd(params,indices)</code>:</p>
<ul>
<li><code>params</code>: input tensor</li>
<li><code>indices</code>: index of the data to be extracted. Generally, this is a multidimensional list.<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Extract the pixel in [1,1] in the first dimension of the first image and pixel in [2,2] in the first dimension of the second image in tensot_h ([4,100,100,3]).</span>
indices <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
tf<span class="token punctuation">.</span>gather_nd<span class="token punctuation">(</span>tensor_h<span class="token punctuation">,</span>indices<span class="token operator">=</span>indices<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5705869, 0.9735735], dtype=float32)&gt;
</code></pre>
<h2 id="tensor-dimension-modification">Tensor Dimension Modification</h2>
<h3 id="dimension-display">Dimension Display</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">const_d_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token comment"># Three common methods for displaying a dimension:</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>const_d_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>const_d_1<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>const_d_1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># The output is a tensor. The value of the tensor indicates the size of the tensor dimension to be displayed.</span>
</code></pre>
<p>Output:</p>
<pre><code>(2, 2)
(2, 2)
tf.Tensor([2 2], shape=(2,), dtype=int32)
</code></pre>
<p>As described above, <code>.shape</code> and <code>.get_shape()</code> return TensorShape objects, while <code>tf.shape(x)</code> returns Tensor objects.</p>
<h3 id="dimension-reshaping">Dimension Reshaping</h3>
<p><code>tf.reshape(tensor,shape,name=None)</code>:</p>
<ul>
<li><code>tensor</code>: input tensor</li>
<li><code>shape</code>: shape of the reshaped tensor<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">reshape_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>reshape_1<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>reshape_1<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[1, 2],
       [3, 4],
       [5, 6]], dtype=int32)&gt;
</code></pre>
<h3 id="dimension-expansion">Dimension Expansion</h3>
<p><code>tf.expand_dims(input,axis,name=None)</code>:</p>
<ul>
<li><code>input</code>: input tensor</li>
<li><code>axis</code>: adds a dimension after the axis dimension. Given an input of <code>D</code> dimensions, axis must be in range <code>[-(D+1), D]</code> (inclusive). A negative value indicates the reverse order.<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.</span>
expand_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>expand_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"add a dimension (axis=0) before the first dimension: "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>expand_sample_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"add a dimension (axis=1) before the second dimension: "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>expand_sample_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"add a dimension (axis=-1) after the last dimension: "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>expand_sample_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (100, 100, 3)
Add a dimension (axis=0) before the first dimension: (1, 100, 100, 3)
Add a dimension (axis=1) before the second dimension: (100, 1, 100, 3)
Add a dimension (axis=-1) after the last dimension: (100, 100, 3, 1)
</code></pre>
<h3 id="dimension-squeezing">Dimension Squeezing</h3>
<p><code>tf.squeeze(input,axis=None,name=None)</code>:<br>
This method is used to remove dimensions of size 1 from the shape of a tensor.</p>
<ul>
<li><code>input</code>: input tensor</li>
<li><code>axis</code>: If you don not want to remove all size 1 dimensions, remove specific size 1 dimensions by specifying axis.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Generate a 100 x 100 x 3 tensor.</span>
orig_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>orig_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
squeezed_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>orig_sample_1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"squeezed data size: "</span><span class="token punctuation">,</span>squeezed_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># The dimension of 'squeeze_sample_2' is [1, 2, 1, 3, 1, 1].</span>
squeeze_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
t_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>squeeze_sample_2<span class="token punctuation">)</span> <span class="token comment"># Dimensions of size 1 are removed.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'t_1.shape:'</span><span class="token punctuation">,</span> t_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># Remove a specific dimension:</span>
<span class="token comment"># 't' is a tensor of shape [1, 2, 1, 3, 1, 1]</span>
t_1_new <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>squeeze_sample_2<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'t_1_new.shape:'</span><span class="token punctuation">,</span> t_1_new<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (1, 100, 100, 3)
Squeezed data size: (100, 100, 3)
t_1.shape: (2, 3)
t_1_new.shape: (1, 2, 3, 1)
</code></pre>
<h3 id="transpose">Transpose</h3>
<p><code>tf.transpose(a,perm=None,conjugate=False,name='transpose')</code>:</p>
<ul>
<li><code>a</code>: input tensor</li>
<li><code>perm</code>: permutation of the dimensions of a, generally used to transpose high-dimensional arrays</li>
<li><code>conjugate</code>: conjugate transpose</li>
<li><code>name</code>: name for the operation<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Low-dimensional transposition is simple. Input the tensor to be transposed by calling tf.transpose.</span>
trans_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>trans_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
transposed_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>trans_sample_1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"transposed data size: "</span><span class="token punctuation">,</span>transposed_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (2, 3)
Transposed data size: (3, 2)
</code></pre>
<p>The perm parameter is required for transposing high-dimensional data. perm indicates the permutation of the dimensions of the input tensor.</p>
<p>For a three-dimensional tensor, its original dimension permutation is <code>[0, 1, 2]</code> (perm), indicating the length, width, and height of the high-dimensional data, respectively.<br>
By changing the value sequence in perm, you can transpose the corresponding dimension of the data.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Generate a 4 x 100 x 200 x 3 tensor to represent four 100 x 200 three-channel color images.</span>
trans_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>trans_sample_2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># Exchange the length and width of the four images. The value range of perm is changed from [0,1,2,3] to [0,2,1,3].</span>
transposed_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>trans_sample_2<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"transposed data size: "</span><span class="token punctuation">,</span>transposed_sample_2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (4, 100, 200, 3)
Transposed data size: (4, 200, 100, 3)
</code></pre>
<h3 id="broadcast-broadcast_to">Broadcast (<code>broadcast_to</code>)</h3>
<p><code>broadcast_to</code> is used to broadcast data from a low dimension to a high dimension.<br>
<code>tf.broadcast_to(input,shape,name=None)</code>:</p>
<ul>
<li><code>input</code>: input tensor</li>
<li><code>shape</code>: size of the output tensor</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">broadcast_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data: "</span><span class="token punctuation">,</span>broadcast_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
broadcasted_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>broadcast_to<span class="token punctuation">(</span>broadcast_sample_1<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"broadcast data: "</span><span class="token punctuation">,</span>broadcasted_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data: [1 2 3 4 5 6]
Broadcast data: [[1 2 3 4 5 6]
 [1 2 3 4 5 6]
 [1 2 3 4 5 6]
 [1 2 3 4 5 6]]
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># During the operation, if two arrays have different shapes, TensorFlow automatically triggers the broadcast mechanism as NumPy does.</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor([[ 1  2  3]
 [11 12 13]
 [21 22 23]
 [31 32 33]], shape=(4, 3), dtype=int32)
</code></pre>
<h2 id="arithmetic-operations-on-tensors">Arithmetic Operations on Tensors</h2>
<h3 id="arithmetic-operators">Arithmetic Operators</h3>
<p>Arithmetic operations include addition (<code>tf.add</code>), subtraction (<code>tf.subtract</code>), multiplication (<code>tf.multiply</code>), division (<code>tf.divide</code>), logarithm (<code>tf.math.log</code>), and powers (<code>tf.pow</code>). The following is an example of addition.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor([[ 4 11]
           [ 6 17]], shape=(2, 2), dtype=int32)
</code></pre>
<h3 id="matrix-multiplication">Matrix Multiplication</h3>
<p>Matrix multiplication is implemented by calling <code>tf.matmul</code>.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=array([[13, 63],
                                                    [20, 96]], dtype=int32)&gt;
</code></pre>
<h3 id="tensor-statistics-collection">Tensor Statistics Collection</h3>
<p>Methods for collecting tensor statistics include:</p>
<ul>
<li><code>tf.reduce_min/max/mean()</code>: calculates the minimum, maximum, and mean values.</li>
<li><code>tf.argmax()</code>/<code>tf.argmin()</code>: calculates the positions of the maximum and minimum values.</li>
<li><code>tf.equal()</code>: checks whether two tensors are equal by element.</li>
<li><code>tf.unique()</code>: removes duplicate elements from a tensor.</li>
<li><code>tf.nn.in_top_k(prediction, target, K)</code>: calculates whether the predicted value is equal to the actual value and returns a tensor of the Boolean type.<br>
The following demonstrates how to use <code>tf.argmax()</code>.<br>
Return the subscript of the maximum value.<br>
<code>tf.argmax(input,axis)</code>:</li>
<li><code>input</code>: input tensor</li>
<li><code>axis</code>: The maximum value is output based on the axis dimension.<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">argmax_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input tensor: "</span><span class="token punctuation">,</span>argmax_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
max_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>argmax_sample_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
max_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>argmax_sample_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"locate the maximum value by column: "</span><span class="token punctuation">,</span>max_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"locate the maximum value by row: "</span><span class="token punctuation">,</span>max_sample_2<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Input tensor: [1 3 2]
 [2 5 8]
 [7 5 9]]
Locate the maximum value by column: [2 1 2].
Locate the maximum value by row: [1 2 2].
</code></pre>
<h2 id="dimension-based-arithmetic-operations">Dimension-based Arithmetic Operations</h2>
<p>In TensorFlow, operations such as <code>tf.reduce_*</code> reduce tensor dimensions. These operations can be performed on the dimension elements of a tensor, for example, calculating the mean value by row and calculating a product of all elements in the tensor.<br>
Common operations include <code>tf.reduce_sum</code> (addition), <code>tf.reduce_prod</code> (multiplication), <code>tf.reduce_min</code> (minimum), <code>tf.reduce_max</code> (maximum), <code>tf.reduce_mean</code> (mean), <code>tf.reduce_all</code> (logical AND), tf.reduce_any (logical OR), and <code>tf.reduce_logsumexp</code> (<code>log(sum(exp))</code>).<br>
The methods of using these operations are similar. The following uses the <code>tf.reduce_sum</code> operation as an example.<br>
Compute the sum of elements across dimensions of a tensor.<br>
<code>tf.reduce_sum(input_tensor, axis=None, keepdims=False,name=None)</code>:</p>
<ul>
<li><code>input_tensor</code>: tensor to reduce</li>
<li><code>axis</code>: axis to be calculated. If this parameter is not specified, the mean value of all elements is calculated.</li>
<li><code>keepdims</code>: whether to reduce the dimension. If this parameter is set to True, the output result retains the shape of the input tensor. If this parameter is set to False, the dimension of the output result is reduced.</li>
<li><code>name</code>: name for the operation<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">reduce_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data"</span><span class="token punctuation">,</span>reduce_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"compute the sum of all elements in a tensor (axis=None): "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>reduce_sample_1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"compute the sum of each column by column (axis=0): "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>reduce_sample_1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"compute the sum of each column by row (axis=1): "</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>reduce_sample_1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data [1 2 3]
 [4 5 6]]
Compute the sum of all elements in the tensor (axis=None): 21
Compute the sum of each column (axis=0): [5 7 9]
Compute the sum of each column (axis=1): [6 15]
</code></pre>
<h2 id="tensor-concatenation-and-splitting">Tensor Concatenation and Splitting</h2>
<h3 id="tensor-concatenation">Tensor Concatenation</h3>
<p>In TensorFlow, tensor concatenation operations include:</p>
<ul>
<li><code>tf.contact()</code>: concatenates tensors along one dimension. Other dimensions remain unchanged.</li>
<li><code>tf.stack()</code>: stacks the tensor list of rank R into a tensor of rank (R+1). Dimensions are changed after stacking.<br>
<code>tf.concat(values, axis, name='concat')</code>:</li>
<li><code>values</code>: input tensor</li>
<li><code>axis</code>: dimension along which to concatenate</li>
<li><code>name</code>: name for the operation<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">concat_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
concat_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>concat_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>concat_sample_2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
concated_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>concat_sample_1<span class="token punctuation">,</span>concat_sample_2<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"concatenated data size: "</span><span class="token punctuation">,</span>concated_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>original data size: (4, 100, 100, 3) (40, 100, 100, 3)
concatenated data size: (44, 100, 100, 3)
</code></pre>
<p>A dimension is added to an original matrix in the same way. axis determines the position where the dimension is added.<br>
<code>tf.stack(values, axis=0, name='stack')</code>:</p>
<ul>
<li><code>values</code>: a list of tensor objects with the same shape and type</li>
<li><code>axis</code>: axis to stack along</li>
<li><code>name</code>: name for the operation<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">stack_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
stack_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Print<span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>stack_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> stack_sample_2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># Dimension addition after concatenating. If axis is set to 0, a dimension is added before the first dimension.</span>
stacked_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>stack_sample_1<span class="token punctuation">,</span> stack_sample_2<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"concatenated data size: "</span><span class="token punctuation">,</span>stacked_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (100, 100, 3) (100, 100, 3)
Concatenated data size: (2, 100, 100, 3)
</code></pre>
<h3 id="tensor-splitting">Tensor Splitting</h3>
<p>In TensorFlow, tensor splitting operations include:</p>
<ul>
<li><code>tf.unstack()</code>: unpacks tensors along the specific dimension.</li>
<li><code>tf.split()</code>: splits a tensor into a list of sub tensors based on specific dimensions.<br>
Compared with tf.unstack(), tf.split() is more flexible.<br>
<code>tf.unstack(value,num=None,axis=0,name='unstack')</code>:</li>
<li><code>value</code>: input tensor</li>
<li><code>num</code>: outputs a list containing num elements. num must be equal to the number of elements in the specified dimension. Generally, this parameter is ignored.</li>
<li><code>axis</code>: axis to unstack along</li>
<li><code>name</code>: name for the operation<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Unpack data along the first dimension and output the unpacked data in a list.</span>
tf<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>stacked_sample_1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>[&lt;tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=
 array([[[ 0.0665694 ,  0.7110351 ,  1.907618  ],
         [ 0.84416866,  1.5470593 , -0.5084871 ],
         [-1.9480026 , -0.9899087 , -0.09975405],
         ...,
</code></pre>
<p><code>tf.split(value, num_or_size_splits, axis=0)</code>:</p>
<ul>
<li><code>value</code>: input tensor</li>
<li><code>num_or_size_splits</code>: number of splits</li>
<li><code>axis</code>: dimension along which to split<br>
<code>tf.split()</code> can be split in either of the following ways:<br>
If <code>num_or_size_splits</code> is an integer, the tensor is evenly split into several small tensors along the <code>axis=D</code> dimension.<br>
If <code>num_or_size_splits</code> is a vector, the tensor is split into several smaller tensors based on the element values of the vector along the <code>axis=D</code> dimension.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
split_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"original data size: "</span><span class="token punctuation">,</span>split_sample_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
splited_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>split_sample_1<span class="token punctuation">,</span> num_or_size_splits<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"If m_or_size_splits is 5, the size of the split data is: "</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>splited_sample_1<span class="token punctuation">)</span><span class="token punctuation">)</span>
splited_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>split_sample_1<span class="token punctuation">,</span> num_or_size_splits<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"If num_or_size_splits is [3,5,2], the sizes of the split data are:"</span><span class="token punctuation">,</span>
      np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>splited_sample_2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>splited_sample_2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>splited_sample_2<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Original data size: (10, 100, 100, 3)
If m_or_size_splits is 5, the size of the split data is (5, 2, 100, 100, 3).
If num_or_size_splits is [3,5,2], the sizes of the split data are (3, 100, 100, 3) (5, 100, 100, 3) (2, 100, 100, 3).
</code></pre>
<h2 id="tensor-sorting">Tensor Sorting</h2>
<p>In TensorFlow, tensor sorting operations include:</p>
<ul>
<li><code>tf.sort()</code>: sorts tensors in ascending or descending order and returns the sorted tensors.</li>
<li><code>tf.argsort()</code>: sorts tensors in ascending or descending order and returns the indices.</li>
<li><code>tf.nn.top_k()</code>: returns the k largest values.<br>
<code>tf.sort/argsort(input, direction, axis)</code>:</li>
<li><code>input</code>: input tensor</li>
<li><code>direction</code>: direction in which to sort the values. The value can be DESCENDING or ASCENDING. The default value is ASCENDING.</li>
<li><code>axis</code>: axis along which to sort The default value is -1, which sorts the last axis.<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">sort_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input tensor: "</span><span class="token punctuation">,</span>sort_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sorted_sample_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>sort_sample_1<span class="token punctuation">,</span> direction<span class="token operator">=</span><span class="token string">"ASCENDING"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"tensor sorted in ascending order: "</span><span class="token punctuation">,</span>sorted_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sorted_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>sort_sample_1<span class="token punctuation">,</span>direction<span class="token operator">=</span><span class="token string">"ASCENDING"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"index of elements in ascending order: "</span><span class="token punctuation">,</span>sorted_sample_2<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Input tensor: [1 8 7 9 6 5 4 2 3 0]
Tensor sorted in ascending order: [0 1 2 3 4 5 6 7 8 9]
Index of elements in ascending order: [9 0 7 8 6 5 4 2 1 3]
</code></pre>
<p><code>tf.nn.top_k(input,K,sorted=True)</code>:</p>
<ul>
<li><code>input</code>: input tensor</li>
<li><code>K</code>: k largest values to be output and their indices</li>
<li><code>sorted</code>: <code>sorted=True</code> indicates in ascending order. <code>sorted=False</code> indicates in descending order.<br>
Two tensors are returned:</li>
<li><code>values</code>: k largest values in each row</li>
<li><code>indices</code>: indices of values within the last dimension of input<br>
Code:</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">values<span class="token punctuation">,</span> index <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>top_k<span class="token punctuation">(</span>sort_sample_1<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input tensor: "</span><span class="token punctuation">,</span>sort_sample_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"k largest values in ascending order: "</span><span class="token punctuation">,</span> values<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"indices of the k largest values in ascending order: "</span><span class="token punctuation">,</span> index<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Input tensor: [1 8 7 9 6 5 4 2 3 0]
The k largest values in ascending order: [9 8 7 6 5]
Indices of the k largest values in ascending order: [3 1 2 4 5]
</code></pre>
<h2 id="eager-execution-mode-of-tensorflow-2">Eager Execution Mode of TensorFlow 2</h2>
<h3 id="eager-execution-mode">Eager execution mode:</h3>
<p>The eager execution mode of TensorFlow is a type of imperative programming, which is the same as the native Python. When you perform a particular operation, the system immediately returns a result.</p>
<h3 id="graph-mode">Graph mode:</h3>
<p>TensorFlow 1 adopts the graph mode to first build a computational graph, enable a session, and then feed actual data to obtain a result.<br>
In eager execution mode, code debugging is easier, but the code execution efficiency is lower.<br>
The following implements simple multiplication by using TensorFlow to compare the differences between the eager execution mode and the graph mode.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">x <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>dtypes<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>dtypes<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
z <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor([[4. 6.]
           [4. 6.]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Use the syntax of TensorFlow 1.x in TensorFlow 2.x. You can install the v1 compatibility package in TensorFlow 2 to inherit the TensorFlow 1.x code and disable the eager execution mode.</span>
<span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1 <span class="token keyword">as</span> tf
tf<span class="token punctuation">.</span>disable_eager_execution<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Create a graph and define it as a computational graph.</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>dtypes<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>dtypes<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token comment"># Start a session and perform the multiplication operation to obtain data.</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>[[4. 6.]
 [4. 6.]]
</code></pre>
<p>Restart the kernel to restore TensorFlow to version 2 and enable the eager execution mode. Another advantage of the eager execution mode lies in availability of native Python functions, such as the following condition statement:</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
thre_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>thre_1<span class="token punctuation">)</span>
<span class="token keyword">if</span> thre_1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor(0.11304152, shape=(), dtype=float32)
</code></pre>
<p>With the eager execution mode, this dynamic control flow can generate a NumPy value extractable by a tensor, without using operators such as <code>tf.cond</code> and <code>tf.while</code> provided in the graph mode.</p>
<h2 id="autograph-of-tensorflow-2">AutoGraph of TensorFlow 2</h2>
<p>When used to comment out a function, the tf.function decorator can be called like any other function. tf.function will be compiled into a graph, so that it can run more efficiently on a GPU or TPU. In this case, the function becomes an operation in TensorFlow. The function can be directly called to output a return value. However, the function is executed in graph mode and the intermediate variable values cannot be directly viewed.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">@tf<span class="token punctuation">.</span>function
<span class="token keyword">def</span> <span class="token function">simple_nn_layer</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span>x<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>w<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token punctuation">)</span>

w <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>

simple_nn_layer<span class="token punctuation">(</span>w<span class="token punctuation">,</span>x<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Tensor("b:0", shape=(), dtype=float32)
&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1.4121541 , 1.1626956 , 1.2527422 ],
       [1.2903953 , 1.0956903 , 1.1309073 ],
       [1.1039395 , 0.92851776, 1.0752096 ]], dtype=float32)&gt;
</code></pre>
<p>According to the output result, the value of b in the function cannot be directly viewed, but the return value can be viewed using <code>.numpy()</code>.</p>
<p>The following compares the performance of the graph and eager execution modes by performing the same operation (LSTM computation of one layer).</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Use the timeit module to measure the execution time of a small code segment.</span>
<span class="token keyword">import</span> timeit
<span class="token comment"># Create a convolutional layer.</span>
CNN_cell <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Use @tf.function to convert the operation into a graph.</span>
@tf<span class="token punctuation">.</span>function
<span class="token keyword">def</span> <span class="token function">CNN_fn</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> CNN_cell<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

image <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Compare the execution time of the two modes.</span>
CNN_cell<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
CNN_fn<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token comment"># Call timeit.timeit to measure the time required for executing the code 10 times.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:"</span><span class="token punctuation">,</span> timeit<span class="token punctuation">.</span>timeit<span class="token punctuation">(</span><span class="token keyword">lambda</span><span class="token punctuation">:</span> CNN_cell<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">,</span> number<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Time required for performing the computation of one CNN layer in graph mode:"</span><span class="token punctuation">,</span> timeit<span class="token punctuation">.</span>timeit<span class="token punctuation">(</span><span class="token keyword">lambda</span><span class="token punctuation">:</span> CNN_fn<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">,</span> number<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Time required for performing the computation of one CNN layer in eager execution mode: 18.26327505100926
Time required for performing the computation of one CNN layer in graph mode: 6.740775318001397
</code></pre>
<p>The comparison shows that the code execution efficiency in graph mode is much higher. Therefore, the <code>@tf.function</code> can be used to improve the code execution efficiency.</p>
<hr>
<h1 id="common-modules-of-tensorflow-2">Common Modules of TensorFlow 2</h1>
<h2 id="introduction-1">Introduction</h2>
<p>This section describes the common modules of TensorFlow 2, including:</p>
<ul>
<li><code>tf.data</code>: implements operations on datasets.
<ul>
<li>These operations include reading datasets from the memory, reading CSV files, reading TFRecord files, and augmenting data.</li>
</ul>
</li>
<li><code>tf.image</code>: implements image processing.
<ul>
<li>These operations include image luminance transformation, saturation transformation, image size transformation, image rotation, and edge detection.</li>
</ul>
</li>
<li><code>tf.gfile</code>: implements operations on files.
<ul>
<li>These operations include reading, writing, and renaming files, and operating folders.</li>
</ul>
</li>
<li><code>tf.keras</code>: a high-level API used to build and train deep learning models.</li>
<li><code>tf.distributions</code> and other modules<br>
This section focuses on the <code>tf.keras</code> module to lay a foundation for deep learning modeling.</li>
</ul>
<h3 id="objectives-1">Objectives</h3>
<p>Upon completion of this exercise, you will be able to master the common deep learning modeling interfaces of <code>tf.keras</code>.</p>
<h2 id="model-building">Model Building</h2>
<p>Stacking a Model (<code>tf.keras.Sequential</code>)<br>
The most common way to build a model is to stack layers by using <code>tf.keras.Sequential</code>.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">as</span> layers 
model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>2.0.0-beta1
2.2.4-tf
</code></pre>
<h3 id="building-a-functional-model">Building a Functional Model</h3>
<p>Functional models are mainly built by using tf.keras.Input and tf.keras.Model, which are more complex than <code>tf.keras.Sequential</code> but have a good effect. Variables can be input at the same time or in different phases, and data can be output in different phases. Functional models are preferred if more than one model output is needed.</p>
<p>Stacked model (.Sequential) vs. functional model (.Model):The <code>tf.keras.Sequential</code> model is a simple stack of layers that cannot represent arbitrary models. You can use the Keras functional API to build complex model topologies, for example:</p>
<ul>
<li>Multi-input models</li>
<li>Multi-output models</li>
<li>Models with shared layers</li>
<li>Models with non-sequential data flows (for example, residual connections)</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Use the output of the current layer as the input of the next layer.</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
h1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
h2 <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>h1<span class="token punctuation">)</span>
y <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>h2<span class="token punctuation">)</span>
model_sample_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment"># Print model information.</span>
model_sample_2<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32)]              0         
_________________________________________________________________
dense_3 (Dense)              (None, 32)                1056      
_________________________________________________________________
dense_4 (Dense)              (None, 32)                1056      
_________________________________________________________________
dense_5 (Dense)              (None, 10)                330       
=================================================================
Total params: 2,442
Trainable params: 2,442
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h3 id="building-a-network-layer-tf.keras.layers">Building a Network Layer (<code>tf.keras.layers</code>)</h3>
<p>The <code>tf.keras.layers</code> module is used to configure neural network layers. Common classes include:</p>
<ul>
<li><code>tf.keras.layers.Dense</code>: builds a fully connected layer.</li>
<li><code>tf.keras.layers.Conv2D</code>: builds a two-dimensional convolutional layer.</li>
<li><code>tf.keras.layers.MaxPooling2D/AveragePooling2D</code>: builds a maximum/average pooling layer.</li>
<li><code>tf.keras.layers.RNN</code>: Builds a recurrent neural network layer.</li>
<li><code>tf.keras.layers.LSTM</code>/<code>tf.keras.layers.LSTMCell</code>: builds an LSTM network layer/LSTM unit.</li>
<li><code>tf.keras.layers.GRU</code>/<code>tf.keras.layers.GRUCell</code>: builds a GRU unit/GRU network layer.</li>
<li><code>tf.keras.layers.Embedding</code>: converts a positive integer (subscript) into a vector of a fixed size, for example, converts <code>[[4],[20]]</code> into <code>[[0.25,0.1],[0.6,-0.2]]</code>. The embedding layer can be used only as the first model layer.</li>
<li><code>tf.keras.layers.Dropout</code>: builds the dropout layer.<br>
The following describes <code>tf.keras.layers.Dense</code>, <code>tf.keras.layers.Conv2D</code>, <code>tf.keras.layers.MaxPooling2D/AveragePooling2D</code>, and <code>tf.keras.layers.LSTM/tf.keras.layers.LSTMCell</code>.<br>
The main network configuration parameters in <code>tf.keras.layers</code> include:</li>
<li><code>activation</code>: sets the activation function of a layer. By default, the system does not use any activation functions.</li>
<li><code>kernel_initializer</code> and <code>bias_initializer</code>: initialization schemes that create a layer’s weights (kernel and bias). This defaults to the Glorot uniform initializer.</li>
<li><code>kernel_regularizer</code> and <code>bias_regularizer</code>: regularization schemes that apply to a layer’s weights (kernel and bias), for example, L1 or L2 regularization. By default, the system does not use regularization functions.</li>
</ul>
<h4 id="tf.keras.layers.dense"><code>tf.keras.layers.Dense</code></h4>
<p>Main configuration parameters in <code>tf.keras.layers.Dense</code> include:</p>
<ul>
<li><code>units</code>: number of neurons</li>
<li><code>activation</code>: activation function</li>
<li><code>use_bias</code>: whether to use the bias terms. Bias terms are used by default.</li>
<li><code>kernel_initializer</code>: initialization scheme that creates a layer’s weight (kernel)</li>
<li><code>bias_initializer</code>: initialization scheme that creates a layer’s weight (bias)</li>
<li><code>kernel_regularizer</code>: regularization scheme that applies a layer’s weight (kernel)</li>
<li><code>bias_regularizer</code>: regularization scheme that applies a layer’s weight (bias)</li>
<li><code>activity_regularizer</code>: regular item applied to the output, a Regularizer object</li>
<li><code>kernel_constraint</code>: constraint applied to a weight</li>
<li><code>bias_constraint</code>: constraint applied to a weight</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Create a fully connected layer that contains 32 neurons and set the activation function to sigmoid.</span>
<span class="token comment"># The activation parameter can be set to a function name string, for example, sigmoid, or a function object, for example, tf.sigmoid.</span>
layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span>

<span class="token comment"># Set kernel_initializer.</span>
layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>he_normal<span class="token punctuation">)</span>
<span class="token comment"># Set kernel_regularizer to the L2 regularization.</span>
layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>l2<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;TensorFlow.python.keras.layers.core.Dense at 0x130c519e8&gt;
</code></pre>
<h4 id="tf.keras.layers.conv2d"><code>tf.keras.layers.Conv2D</code></h4>
<p>Main configuration parameters in <code>tf.keras.layers.Conv2D</code> include:</p>
<ul>
<li><code>filters</code>: number of convolution kernels (output dimensions)</li>
<li><code>kernel_size</code>: width and length of a convolution kernel</li>
<li><code>strides</code>: convolution stride</li>
<li><code>padding</code>: zero padding policy
<ul>
<li>When padding is set to valid, only valid convolution is performed, that is, boundary data is not processed. When padding is set to same, the convolution result at the boundary is reserved, and consequently, the output shape is usually the same as the input shape.</li>
</ul>
</li>
<li><code>activation</code>: activation function</li>
<li><code>data_format</code>: data format. The value can be <code>channels_first</code> or <code>channels_last</code>. For example, for a 128 x 128 RGB image, data is organized as <code>(3,128,128)</code> if the value is <code>channels_first</code>, and as <code>(128,128,3)</code> if the value is <code>channels_last</code>. The default value of this parameter is the value defined in <code>~/.keras/keras.json</code>. If the value has never been set, the default value is <code>channels_last</code>.<br>
Other parameters include <code>use_bias</code>, <code>kernel_initializer</code>, <code>bias_initializer</code>, <code>kernel_regularizer</code>, <code>bias_regularizer</code>, <code>activity_regularizer</code>, <code>kernel_constraints</code>, and <code>bias_constraints</code>.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;TensorFlow.python.keras.layers.convolutional.Conv2D at 0x106c510f0&gt;
</code></pre>
<h4 id="tf.keras.layers.maxpooling2daveragepooling2d"><code>tf.keras.layers.MaxPooling2D/AveragePooling2D</code></h4>
<p>Main configuration parameters in tf.keras.layers.MaxPooling2D/AveragePooling2D include:</p>
<ul>
<li><code>pool_size</code>: size of the pooled kernel. For example, if the matrix <code>(2, 2)</code> is used, the image becomes half of the original length in both dimensions. If this parameter is set to an integer, the integer is the value of all dimensions.</li>
<li><code>strides</code>: stride value.<br>
Other parameters include <code>padding</code> and <code>data_format</code>.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>&lt;TensorFlow.python.keras.layers.pooling.MaxPooling2D at 0x132ce1f98&gt;
</code></pre>
<h4 id="tf.keras.layers.lstmtf.keras.layers.lstmcell"><code>tf.keras.layers.LSTM/tf.keras.layers.LSTMCell</code></h4>
<p>Main configuration parameters in <code>tf.keras.layers.LSTM</code>/<code>tf.keras.layers.LSTMCell</code> include:</p>
<ul>
<li><code>units</code>: output dimension</li>
<li><code>input_shape</code> <code>(timestep, input_dim)</code>: <code>timestep</code> can be set to None, and <code>input_dim</code> indicates the input data dimensions.</li>
<li><code>activation</code>: activation function</li>
<li><code>recurrent_activation</code>: activation function to use for the recurrent step</li>
<li><code>return_sequences</code>: If the value is True, all sequences are returned. If the value is False, the output in the last cell of the output sequence is returned.</li>
<li><code>return_state</code>: Boolean value, indicating whether to return the last state in addition to the output.</li>
<li><code>dropout</code>: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the inputs</li>
<li><code>recurrent_dropout</code>: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the recurrent state</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
lstm <span class="token operator">=</span> layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
model_lstm_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>inputs<span class="token punctuation">,</span> outputs<span class="token operator">=</span>lstm<span class="token punctuation">)</span>

inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
lstm <span class="token operator">=</span> layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
model_lstm_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>inputs<span class="token punctuation">,</span> outputs<span class="token operator">=</span>lstm<span class="token punctuation">)</span>

<span class="token comment"># Sequences t1, t2, and t3</span>
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Output when return_sequences is set to True"</span><span class="token punctuation">,</span>model_lstm_1<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Output when return_sequences is set to False"</span><span class="token punctuation">,</span>model_lstm_2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>[[[0.1], [0.2], [0.3]]]
Output when return_sequences is set to True: [[[-0.0106758 ]
  [-0.02711176]
  [-0.04583194]]]
Output when return_sequences is set to False: [[0.05914127]]
</code></pre>
<p><code>LSTMcell</code> is the implementation unit of the LSTM layer.</p>
<ul>
<li><code>LSTM</code> is an LSTM network layer.</li>
<li><code>LSTMCell</code> is a single-step computing unit, that is, an LSTM unit.</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#LSTM</span>
tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#LSTMCell</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> layers<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTMCell<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
model_lstm_3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre>
<h2 id="training-and-evaluation">Training and Evaluation</h2>
<h3 id="model-compilation">Model Compilation</h3>
<p>After a model has been built, call compile to configure its learning process:</p>
<ul>
<li><code>compile( optimizer='rmsprop', loss=None, metrics=None, loss_weights=None)</code>:
<ul>
<li><code>optimizer</code>: optimizer</li>
<li><code>loss</code>: loss function, cross entropy for binary tasks and MSE for regression tasks</li>
<li><code>metrics</code>: model evaluation criteria during training and testing. For example, metrics can be set to [‘accuracy’]. To specify multiple evaluation criteria, transfer a dictionary. For example, set metrics to {‘output_a’:‘accuracy’}.<br>
<code>loss_weights</code>: If the model has multiple task outputs, you need to specify a weight for each output when optimizing the global loss.<br>
Code:</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># Determine the optimizer, loss function, and model evaluation method (metrics).</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>categorical_crossentropy<span class="token punctuation">,</span>
             metrics<span class="token operator">=</span><span class="token punctuation">[</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>categorical_accuracy<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="model-training">Model Training</h3>
<p><code>fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)</code>:</p>
<ul>
<li><code>x</code>: input training data</li>
<li><code>y</code>: target (labeled) data</li>
<li><code>batch_size</code>: number of samples for each gradient update. The default value 32.</li>
<li><code>epochs</code>: number of iteration rounds of the training model</li>
<li><code>verbose</code>: log display mode. The value can be 0, 1, or 2.
<ul>
<li>0 = no display</li>
<li>1 = progress bar</li>
<li>2 = one line for each round</li>
</ul>
</li>
<li><code>callbacks</code>: callback function used during training</li>
<li><code>validation_split</code>: ratio of the validation dataset to the training data</li>
<li><code>validation_data</code>: validation dataset. This parameter overwrites validation_split.</li>
<li><code>shuffle</code>: whether to shuffle data before each round of iteration. This parameter is invalid when steps_per_epoch is not None.</li>
<li><code>initial_epoch</code>: epoch at which to start training (useful for resuming a previous training weight)</li>
<li><code>steps_per_epoch</code>: set to the dataset size or batch_size</li>
<li><code>validation_steps</code>: Total number of steps (batches of samples) to be validated before stopping. This parameter is valid only when <code>steps_per_epoch</code> is specified.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

train_x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

val_x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
val_y <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
          validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_x<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Train on 1000 samples, validate on 200 samples
Epoch 1/10
1000/1000 [==============================] - 0s 488us/sample - loss: 12.6024 - categorical_accuracy: 0.0960 - val_loss: 12.5787 - val_categorical_accuracy: 0.0850
Epoch 2/10
1000/1000 [==============================] - 0s 23us/sample - loss: 12.6007 - categorical_accuracy: 0.0960 - val_loss: 12.5776 - val_categorical_accuracy: 0.0850
Epoch 3/10
1000/1000 [==============================] - 0s 31us/sample - loss: 12.6002 - categorical_accuracy: 0.0960 - val_loss: 12.5771 - val_categorical_accuracy: 0.0850
...
Epoch 10/10
1000/1000 [==============================] - 0s 24us/sample - loss: 12.5972 - categorical_accuracy: 0.0960 - val_loss: 12.5738 - val_categorical_accuracy: 0.0850

&lt;TensorFlow.python.keras.callbacks.History at 0x130ab5518&gt;
</code></pre>
<p>For large datasets, you can use <code>tf.data</code> to build training input pipelines.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>val_x<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> val_dataset<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> val_dataset<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> steps_per_epoch<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>
          validation_data<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span> validation_steps<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Train for 30 steps, validate for 3 steps
Epoch 1/10
30/30 [==============================] - 0s 15ms/step - loss: 12.6243 - categorical_accuracy: 0.0948 - val_loss: 12.3128 - val_categorical_accuracy: 0.0833
...
30/30 [==============================] - 0s 2ms/step - loss: 12.5797 - categorical_accuracy: 0.0951 - val_loss: 12.3067 - val_categorical_accuracy: 0.0833
&lt;TensorFlow.python.keras.callbacks.History at 0x132ab48d0&gt;
</code></pre>
<h3 id="callback-functions">Callback Functions</h3>
<p>A callback function is an object passed to the model to customize and extend the model’s behavior during training. You can customize callback functions or use embedded functions in <code>tf.keras.callbacks</code>. Common embedded callback functions include:</p>
<ul>
<li><code>tf.keras.callbacks.ModelCheckpoint</code>: periodically saves models.</li>
<li><code>tf.keras.callbacks.LearningRateScheduler</code>: dynamically changes the learning rate.</li>
<li><code>tf.keras.callbacks.EarlyStopping</code>: stops the training in advance.</li>
<li><code>tf.keras.callbacks.TensorBoard</code>: uses the TensorBoard.</li>
</ul>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> os
<span class="token comment"># Set hyperparameters.</span>
Epochs <span class="token operator">=</span> <span class="token number">10</span>
logdir<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span>
<span class="token comment"># Define a function for dynamically setting the learning rate.</span>
<span class="token keyword">def</span> <span class="token function">lr_Scheduler</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> epoch <span class="token operator">&gt;</span> <span class="token number">0.9</span> <span class="token operator">*</span> Epochs<span class="token punctuation">:</span>
        lr <span class="token operator">=</span> <span class="token number">0.0001</span>
    <span class="token keyword">elif</span> epoch <span class="token operator">&gt;</span> <span class="token number">0.5</span> <span class="token operator">*</span> Epochs<span class="token punctuation">:</span>
        lr <span class="token operator">=</span> <span class="token number">0.001</span>
    <span class="token keyword">elif</span> epoch <span class="token operator">&gt;</span> <span class="token number">0.25</span> <span class="token operator">*</span> Epochs<span class="token punctuation">:</span>
        lr <span class="token operator">=</span> <span class="token number">0.01</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        lr <span class="token operator">=</span> <span class="token number">0.1</span>
        
    <span class="token keyword">print</span><span class="token punctuation">(</span>lr<span class="token punctuation">)</span>
    <span class="token keyword">return</span> lr

callbacks <span class="token operator">=</span> <span class="token punctuation">[</span>
   <span class="token comment"># Early stopping:</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>
        <span class="token comment"># Metric for determining whether the model performance has no further improvement</span>
        monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>
        <span class="token comment"># Threshold for determining whether the model performance has no further improvement</span>
        min_delta<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>
        <span class="token comment"># Number of epochs in which the model performance has no further improvement</span>
        patience<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    
    <span class="token comment"># Periodically save models.</span>
     tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span>
        <span class="token comment"># Model path</span>
        filepath<span class="token operator">=</span><span class="token string">'testmodel_{epoch}.h5'</span><span class="token punctuation">,</span>
        <span class="token comment"># Determine whether to save the optimal model.</span>
        save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    
    <span class="token comment"># Dynamically change the learning rate.</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>LearningRateScheduler<span class="token punctuation">(</span>lr_Scheduler<span class="token punctuation">)</span><span class="token punctuation">,</span>

    <span class="token comment"># Use the TensorBoard.</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>TensorBoard<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>logdir<span class="token punctuation">)</span>
<span class="token punctuation">]</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span>Epochs<span class="token punctuation">,</span>callbacks<span class="token operator">=</span>callbacks<span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_x<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Train on 1000 samples, validate on 200 samples
0
0.1
Epoch 1/10
1000/1000 [==============================] - 0s 155us/sample - loss: 12.7907 - categorical_accuracy: 0.0920 - val_loss: 12.7285 - val_categorical_accuracy: 0.0750
1
0.1
Epoch 2/10
1000/1000 [==============================] - 0s 145us/sample - loss: 12.6756 - categorical_accuracy: 0.0940 - val_loss: 12.8673 - val_categorical_accuracy: 0.0950
...
0.001
Epoch 10/10
1000/1000 [==============================] - 0s 134us/sample - loss: 12.3627 - categorical_accuracy: 0.1020 - val_loss: 12.3451 - val_categorical_accuracy: 0.0900

&lt;TensorFlow.python.keras.callbacks.History at 0x133d35438&gt;
</code></pre>
<h3 id="evaluation-and-prediction">Evaluation and Prediction</h3>
<p>Evaluation and prediction functions: tf.keras.Model.evaluate and tf.keras.Model.predict.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Model evaluation</span>
test_x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_y <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>1000/1000 [==============================] - 0s 45us/sample - loss: 12.2881 - categorical_accuracy: 0.0770
[12.288104843139648, 0.077]
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Model prediction</span>
pre_x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>[[0.04431767 0.24562006 0.05260926 ... 0.1016549  0.13826898 0.15511878]
 [0.06296062 0.12550288 0.07593573 ... 0.06219672 0.21190381 0.12361749]
 [0.07203944 0.19570401 0.11178136 ... 0.05625525 0.20609994 0.13041474]
 ...
 [0.09224506 0.09908539 0.13944311 ... 0.08630784 0.15009451 0.17172746]
 [0.08499582 0.17338121 0.0804626  ... 0.04409525 0.27150458 0.07133815]
 [0.05191234 0.11740112 0.08346355 ... 0.0842929  0.20141983 0.19982798]]
</code></pre>
<h2 id="model-saving-and-restoration">Model Saving and Restoration</h2>
<p>Saving and Restoring an Entire Model<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment"># Save models.</span>
logdir<span class="token operator">=</span><span class="token string">'./model'</span>
<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>logdir<span class="token operator">+</span><span class="token string">'/the_save_model.h5'</span><span class="token punctuation">)</span>
<span class="token comment"># Import models.</span>
new_model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>logdir<span class="token operator">+</span><span class="token string">'/the_save_model.h5'</span><span class="token punctuation">)</span>
new_prediction <span class="token operator">=</span> new_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
<span class="token comment">#np.testing.assert_allclose: determines whether the similarity of two objects exceeds the specified tolerance. If yes, the system displays an exception.</span>
<span class="token comment">#atol: specified tolerance</span>
np<span class="token punctuation">.</span>testing<span class="token punctuation">.</span>assert_allclose<span class="token punctuation">(</span>result<span class="token punctuation">,</span> new_prediction<span class="token punctuation">,</span> atol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span> <span class="token comment"># Prediction results are the same.</span>
</code></pre>
<p>After a model is saved, you can find the corresponding weight file in the corresponding folder.</p>
<p>Saving and Loading Network Weights Only<br>
If the weight name is suffixed with .h5 or .keras, save the weight as an HDF5 file; otherwise, save the weight as a TensorFlow checkpoint file by default.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">model<span class="token punctuation">.</span>save_weights<span class="token punctuation">(</span><span class="token string">'./model/model_weights'</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save_weights<span class="token punctuation">(</span><span class="token string">'./model/model_weights.h5'</span><span class="token punctuation">)</span>
<span class="token comment"># Load the weights.</span>
model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span><span class="token string">'./model/model_weights'</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span><span class="token string">'./model/model_weights.h5'</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="handwritten-digit-recognition-with-tensorflow">Handwritten Digit Recognition with TensorFlow</h1>
<h2 id="introduction-2">Introduction</h2>
<p>Handwritten digit recognition is a common image recognition task where computers recognize digits in handwritten images. Different from printed fonts, handwriting of different people have different styles and sizes, making it difficult for computers to recognize handwriting. This exercise uses deep learning and TensorFlow tools to train a model using MNIST datasets.<br>
This section describes the basic process of TensorFlow computing and basic elements for building a network.</p>
<h3 id="objectives-2">Objectives</h3>
<p>Understand the basic TensorFlow calculation process;<br>
Be familiar with the basic elements for building a network, including dataset acquisition, network model building, model training, and model validation.</p>
<h3 id="tasks">Tasks</h3>
<ul>
<li>Read the MNIST handwritten digit dataset.</li>
<li>Get started with TensorFlow by using simple mathematical models.</li>
<li>Implement softmax regression by using high-level APIs.</li>
<li>Build a multi-layer CNN.</li>
<li>Implement a CNN by using high-level APIs.</li>
<li>Visualize prediction results.</li>
</ul>
<h2 id="project-description-and-dataset-acquisition">Project Description and Dataset Acquisition</h2>
<h3 id="description">Description</h3>
<p>Handwritten digit recognition is a common image recognition task where computers recognize digits in handwritten images. Different from printed fonts, handwriting of different people have different styles and sizes, making it difficult for computers to recognize handwriting. This exercise uses deep learning and TensorFlow tools to train a model using MNIST datasets.</p>
<h3 id="data-acquisition-and-processing">Data Acquisition and Processing</h3>
<h4 id="about-the-dataset">About the Dataset</h4>
<ol>
<li>The MNIST dataset is provided by the National Institute of Standards and Technology (NIST).</li>
<li>It consists of handwritten digits from 250 different individuals, of which 50% are high school students and 50% are staff from Bureau of the Census.</li>
<li>You can download the dataset from <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>, which consists of the following parts:
<ul>
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 47 MB after decompression, including 60,000 samples)</li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 60 KB after decompression, including 60,000 labels)</li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 7.8 MB after decompression, including 10,000 samples)</li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5 KB, 10 KB after decompression, including 10,000 labels)</li>
</ul>
</li>
<li>The MNIST is an entry-level computer vision dataset that contains images of various handwritten digits.</li>
</ol>
<p>It also contains one label corresponding to each image to clarify the correct digit. For example, the labels for the preceding four images are 5, 0, 4, and 1.</p>
<h4 id="mnist-dataset-reading">MNIST Dataset Reading</h4>
<p>Download the MNIST dataset from the official TensorFlow website and decompress it.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> datasets
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token punctuation">(</span>x_train_raw<span class="token punctuation">,</span> y_train_raw<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test_raw<span class="token punctuation">,</span> y_test_raw<span class="token punctuation">)</span> <span class="token operator">=</span> datasets<span class="token punctuation">.</span>mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>y_train_raw<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train_raw<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_train_raw<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_test_raw<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_test_raw<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># Convert the labels into one-hot codes.</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>
y_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train_raw<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
y_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test_raw<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>5
(60000, 28, 28) (60000,)
(10000, 28, 28) (10000,)
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</code></pre>
<p>In the MNIST dataset, the images is a tensor in the shape of <code>[60000, 28, 28]</code>. The first dimension is used to extract images, and the second and third dimensions are used to extract pixels in each image. Each element in this tensor indicates the strength of a pixel in an image. The value ranges from 0 to 255.<br>
The label data is converted from scalar to one-hot vectors. In a one-hot vector, one digit is 1 and digits in other dimensions are all 0s. For example, label 1 can be represented as <code>[0,1,0,0,0,0,0,0,0,0,0]</code>. Therefore, the labels are a digital matrix of <code>[60000, 10]</code>.</p>
<h3 id="dataset-preprocessing-and-visualization">Dataset Preprocessing and Visualization</h3>
<h4 id="data-visualization">Data Visualization</h4>
<p>Draw the first nine images.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>x_train_raw<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment">#plt.ylabel(y[i].numpy())</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<p>Data processing: The output of a fully connected network must be in the form of vector, instead of the matrix form of the current images. Therefore, you need to sort the images into vectors.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Convert a 28 x 28 image to a 784 x 1 vector.</span>
x_train <span class="token operator">=</span> x_train_raw<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
x_test <span class="token operator">=</span> x_test_raw<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
</code></pre>
<p>Currently, the dynamic range of pixels is 0 to 255. Image pixels are usually normalized to the range of 0 to 1 during processing of image pixel values.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Normalize image pixel values.</span>
x_train <span class="token operator">=</span> x_train<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
x_test <span class="token operator">=</span> x_test<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
</code></pre>
<h3 id="dnn-construction">DNN Construction</h3>
<h4 id="building-a-dnn-model">Building a DNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Create a deep neural network (DNN) model that consists of three fully connected layers and two ReLU activation functions.</span>
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span> 
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_dim <span class="token operator">=</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">124</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<p><code>layer.Dense()</code> indicates a fully connected layer, and activation indicates a used activation function.</p>
<h4 id="compiling-the-dnn-model">Compiling the DNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">Optimizer <span class="token operator">=</span> optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>categorical_crossentropy<span class="token punctuation">,</span>
              optimizer<span class="token operator">=</span>Optimizer<span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>In the preceding example, the loss function of the model is defined as cross entropy, and the optimization algorithm is the Adam gradient descent method.</p>
<h4 id="training-the-dnn-model">Training the DNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Fit the training data to the model by using the fit method.</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span>
          batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>
          epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
          verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Epoch 1/10
60000/60000 [==============================] - 7s 114us/sample - loss: 0.2281 - acc: 0.9327s - loss: 0.2594 - acc: 0. - ETA: 1s - loss: 0.2535 - acc: 0.9 - ETA: 1s - loss:
Epoch 2/10
60000/60000 [==============================] - 8s 129us/sample - loss: 0.0830 - acc: 0.9745s - loss: 0.0814 - ac
Epoch 3/10
60000/60000 [==============================] - 8s 127us/sample - loss: 0.0553 - acc: 0.9822
Epoch 4/10
60000/60000 [==============================] - 7s 117us/sample - loss: 0.0397 - acc: 0.9874s - los
Epoch 5/10
60000/60000 [==============================] - 8s 129us/sample - loss: 0.0286 - acc: 0.9914
Epoch 6/10
60000/60000 [==============================] - 8s 136us/sample - loss: 0.0252 - acc: 0.9919
Epoch 7/10
60000/60000 [==============================] - 8s 129us/sample - loss: 0.0204 - acc: 0.9931s - lo
Epoch 8/10
60000/60000 [==============================] - 8s 135us/sample - loss: 0.0194 - acc: 0.9938
Epoch 9/10
60000/60000 [==============================] - 7s 109us/sample - loss: 0.0162 - acc: 0.9948
Epoch 10/10
60000/60000 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.994 - 7s 117us/sample - loss: 0.0148 - acc: 0.9948
</code></pre>
<p>epoch indicates a specific round of training. In the preceding example, full data is iterated for 10 times.</p>
<h4 id="evaluating-the-dnn-model">Evaluating the DNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">score <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test loss:'</span><span class="token punctuation">,</span> score<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> score<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Test loss: 0.48341113169193267
Test accuracy: 0.8765
</code></pre>
<p>According to the evaluation, the model accuracy is 0.87 after 10 model training iterations.<br>
Saving the DNN Model<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">logdir<span class="token operator">=</span><span class="token string">'./mnist_model'</span>
<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>logdir<span class="token operator">+</span><span class="token string">'/final_DNN_model.h5'</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="cnn-construction">CNN Construction</h3>
<p>The conventional CNN construction method helps you better understand the internal network structure but requires a large code volume. Therefore, attempts to construct a CNN by using high-level APIs are made to simplify the network construction process.</p>
<h3 id="building-a-cnn-model">Building a CNN Model</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

model<span class="token operator">=</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Create a network sequence.</span>
<span class="token comment">## Add the first convolutional layer and pooling layer.</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              padding <span class="token operator">=</span> <span class="token string">'same'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">,</span>input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">'valid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## Add the second convolutional layer and pooling layer.</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding <span class="token operator">=</span> <span class="token string">'same'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">'valid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## Add a dropout layer to reduce overfitting.</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## Add two fully connected layers.</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>In the preceding network, two convolutional layers and pooling layers are first added by using keras.layers. Afterwards, a dropout layer is added to prevent overfitting. Finally, two full connection layers are added.</p>
<h4 id="compiling-and-training-the-cnn-model">Compiling and Training the CNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Expand data dimensions to adapt to the CNN model.</span>
X_train<span class="token operator">=</span>x_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
X_test<span class="token operator">=</span>x_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">"categorical_crossentropy"</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>X_train<span class="token punctuation">,</span>y<span class="token operator">=</span>y_train<span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Epoch 1/5
55000/55000 [==============================] - 49s 899us/sample - loss: 0.2107 - acc: 0.9348
Epoch 2/5
55000/55000 [==============================] - 48s 877us/sample - loss: 0.0793 - acc: 0.9763
Epoch 3/5
55000/55000 [==============================] - 52s 938us/sample - loss: 0.0617 - acc: 0.9815
Epoch 4/5
55000/55000 [==============================] - 48s 867us/sample - loss: 0.0501 - acc: 0.9846
Epoch 5/5
55000/55000 [==============================] - 50s 901us/sample - loss: 0.0452 - acc: 0.9862

&lt;tensorflow.python.keras.callbacks.History at 0x214bbf34ac8&gt;
</code></pre>
<p>During training, the network training data is iterated for only five times. You can increase the number of network iterations to check the effect.</p>
<h4 id="evaluating-the-cnn-model">Evaluating the CNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">test_loss<span class="token punctuation">,</span>test_acc<span class="token operator">=</span>model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x<span class="token operator">=</span>X_test<span class="token punctuation">,</span>y<span class="token operator">=</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Test Accuracy %.2f"</span><span class="token operator">%</span>test_acc<span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>10000/10000 [==============================] - 2s 185us/sample - loss: 0.0239 - acc: 0.9921
Test Accuracy 0.99
</code></pre>
<p>The evaluation shows that the accuracy of the CNN model reaches up to 99%.</p>
<h4 id="saving-the-cnn-model">Saving the CNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">logdir<span class="token operator">=</span><span class="token string">'./mnist_model'</span>
<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>logdir<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>logdir<span class="token operator">+</span><span class="token string">'/final_CNN_model.h5'</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="prediction-result-visualization">Prediction Result Visualization</h3>
<h4 id="loading-the-cnn-model">Loading the CNN Model</h4>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> load_model
new_model <span class="token operator">=</span> load_model<span class="token punctuation">(</span><span class="token string">'./mnist_model/final_CNN_model.h5'</span><span class="token punctuation">)</span>
new_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        832       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout (Dropout)            (None, 7, 7, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 128)               401536    
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 10)                1290      
=================================================================
Total params: 422,154
Trainable params: 422,154
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>Visualize the prediction results.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Visualize the test dataset output.</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">def</span> <span class="token function">res_Visual</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    final_opt_a<span class="token operator">=</span>new_model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># Perform predictions on the test dataset by using the model.</span>
    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>n<span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ncols<span class="token operator">=</span><span class="token number">5</span> <span class="token punctuation">)</span>
    ax <span class="token operator">=</span> ax<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'prediction results of the first {} images:'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>final_opt_a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
       <span class="token comment"># Display images.</span>
        img <span class="token operator">=</span> X_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Read each row of data in Ndarry format.</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'Greys'</span><span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">'nearest'</span><span class="token punctuation">)</span><span class="token comment"># Visualization</span>
        ax<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'first {} images in the test dataset are in the following format:'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>
res_Visual<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>Prediction results of the first 20 images:
7,2,1,0,4, 
1,4,9,5,9, 
0,6,9,0,1, 
5,9,7,3,4, 
First 20 images in the test dataset:
</code></pre>
<h1 id="image-classification">Image Classification</h1>
<h2 id="introduction-3">Introduction</h2>
<h3 id="about-this-exercise-1">About This Exercise</h3>
<p>This exercise is about a basic task in computer vision, that is, image recognition. The NumPy and TensorFlow modules are required. The NumPy module is used to create image objects, and the TensorFlow framework is used to create deep learning algorithms and build CNNs. This exercise recognizes image classes based on the CIFAR10 dataset.</p>
<h3 id="objectives-3">Objectives</h3>
<p>Upon completion of this exercise, you will be able to:</p>
<ul>
<li>Strengthen the understanding of the Keras-based neural network model building process.</li>
<li>Master the method to load a pre-trained model.</li>
<li>Learn how to use the checkpoint function.</li>
<li>Learn how to use a trained model to make predictions.</li>
</ul>
<h2 id="tasks-1">Tasks</h2>
<h3 id="importing-dependencies">Importing Dependencies</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> datasets<span class="token punctuation">,</span> Sequential
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span>Activation<span class="token punctuation">,</span>MaxPooling2D<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>Flatten<span class="token punctuation">,</span>Dense
<span class="token keyword">import</span>  os
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
</code></pre>
<h3 id="preprocessing-data">Preprocessing Data</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Download the dataset.</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Print the dataset size.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Convert the labels.</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>
y_train_onehot <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
y_test_onehot <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
<p>Output:</p>
<pre><code>(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)
[6]

array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)
</code></pre>
<p>Display nine sample images.</p>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Generate an image label list.</span>
category_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">'airplane'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token string">'automobile'</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token string">'bird'</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token string">'cat'</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token string">'deer'</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token string">'dog'</span><span class="token punctuation">,</span>
                 <span class="token number">6</span><span class="token punctuation">:</span><span class="token string">'frog'</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">:</span><span class="token string">'horse'</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">:</span><span class="token string">'ship'</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">:</span><span class="token string">'truck'</span><span class="token punctuation">}</span>
<span class="token comment"># Display the first nine images and their labels.</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>x_train<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>category_dict<span class="token punctuation">[</span>y_train<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<p>First nine images and their labels<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Pixel normalization</span>
x_train <span class="token operator">=</span> x_train<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
x_test <span class="token operator">=</span> x_test<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">255</span>
Building a Model
Code<span class="token punctuation">:</span>
<span class="token keyword">def</span> <span class="token function">CNN_classification_model</span><span class="token punctuation">(</span>input_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    <span class="token comment"># The first two modules have two convolutional layers and one pooling layer.</span>
    <span class="token triple-quoted-string string">'''Conv1 with 32 3*3 kernels 
        padding="same": it applies zero padding to the input image so that the input image gets fully covered by the filter and specified stride.
        It is called SAME because, for stride 1, the output will be the same as the input.
        output: 32*32*32'''</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> 
              input_shape<span class="token operator">=</span>input_size<span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    <span class="token comment">#Conv2</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    <span class="token comment"># The second module</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

   <span class="token comment"># Perform flattening before connecting to the fully connected network.</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
   <span class="token comment"># The dropout layer parameter value ranges from 0 to 1.</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
    opt <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>
    
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>opt<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
<span class="token keyword">return</span> model
model<span class="token operator">=</span>CNN_classification_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<h3 id="training-the-model">Training the Model</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> ModelCheckpoint
model_name <span class="token operator">=</span> <span class="token string">"final_cifar10.h5"</span>
model_checkpoint <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>model_name<span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Load the pre-trained model.</span>
trained_weights_path <span class="token operator">=</span> <span class="token string">'cifar10_weights.h5'</span>
<span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>trained_weights_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span>trained_weights_path<span class="token punctuation">,</span> by_name <span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># Training</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>callbacks <span class="token operator">=</span> <span class="token punctuation">[</span>model_checkpoint<span class="token punctuation">]</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<p>This exercise is performed on a laptop. The network in this exercise is simple, consisting of four convolutional layers. To improve the performance of this model, you can increase the number of epochs and the complexity of the model.</p>
<h3 id="evaluating-the-model">Evaluating the Model</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python">new_model <span class="token operator">=</span> CNN_classification_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
new_model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span><span class="token string">'final_cifar10.h5'</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>10000/10000 [==============================] - 13s 1ms/sample - loss: 0.8581 - accuracy: 0.7042s - loss: 0.854
[0.8581173644065857, 0.7042]
</code></pre>
<h3 id="predict-an-image.">Predict an image.</h3>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Output the possibility of each class.</span>
new_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>array([[2.3494475e-03, 6.9919275e-05, 8.1065837e-03, 7.8556609e-01,
        2.3783690e-03, 1.8864134e-01, 6.8611270e-03, 1.2157968e-03,
        4.3428279e-03, 4.6843957e-04]], dtype=float32)
</code></pre>
<p>Code:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># Output the prediction result.</span>
new_model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<pre><code>array([3])
</code></pre>
<p>Output the first four images and their prediction results.<br>
Code:</p>
<pre class=" language-python"><code class="prism  language-python">pred_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    pred <span class="token operator">=</span> new_model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    pred_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"pred:"</span><span class="token operator">+</span>category_dict<span class="token punctuation">[</span>pred<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"   actual:"</span><span class="token operator">+</span> category_dict<span class="token punctuation">[</span>y_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Output:</p>
<h3 id="images-and-prediction-results">Images and prediction results</h3>
<h2 id="summary">Summary</h2>
<p>This section describes how to build an image classification model based on TensorFlow 2 and Python. It provides trainees with basic concepts in building deep learning models.</p>

    </div>
  </div>
</body>

</html>
